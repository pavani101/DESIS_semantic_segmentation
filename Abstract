## ABSTRACT

Remote sensing plays a crucial role in Earth and environmental sciences, providing valuable data for monitoring and understanding our planet. This technology allows for the collection of spatial information from a distance, enabling researchers to study large areas efficiently. Hyperspectral imaging is an advanced form of remote sensing that collects data across hundreds of narrow, contiguous spectral bands. Hyperspectral image classification is crucial in remote sensing as it allows for accurate segmentation of land cover using sophisticated machine learning methods. This research investigates the performance of two deep learning architectures, namely UNet and the Multi-Layer Perceptron (MLP), in the context of semantic segmentation for hyperspectral images captured by DESIS. The UNet architecture, built upon a ResNet34 backbone, effectively captures spatial characteristics utilizing an encoder-decoder framework. Meanwhile, the MLP focuses on pixel-specific spectral data, extracting distinct features across 235 hyperspectral bands. An extensive collection of stratified hyperspectral samples was used for both training and evaluation, resulting in high classification accuracy for various land cover categories. Comprehensive quantitative and qualitative evaluations, incorporating classification reports, confusion matrices, and segmentation visualizations, reveal both the advantages and drawbacks of each method. The result indicates that deep learning models, such as the UNet, are capable of hyperspectral image classification with 92\% accuracy in capturing spatial features with nominal overfitting. Our baseline model, a simple MLP did not produce acceptable accuracy across all the images, working well for some while doing the opposite for others probably due to the inaccuracies present in the ground truth mask used for training. Our framework and the associated results have the potential to contribute towards efficient processing of hyperspectral images.
